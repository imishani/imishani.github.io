<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="UGG0yB82J5JOXyuEm9OdJ4M6Y0SDSkP0LpEPKRCp81Q"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Itamar Mishani </title> <meta name="author" content="Itamar Mishani"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="robotics, AI, planning, manipulation, RI, CMU, Itamar, Mishani"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?0beb8877742cd9d8e1c35e5fb5551627"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://imishani.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Itamar</span> Mishani </h1> <p class="desc"><a href="https://www.ri.cmu.edu/robotics-groups/search-based-planning-laboratory/" rel="external nofollow noopener" target="_blank">Search-based Planning Lab (SBPL)</a>. <a href="https://www.ri.cmu.edu" rel="external nofollow noopener" target="_blank">Robotics Institute</a>. <a href="https://www.cmu.edu" rel="external nofollow noopener" target="_blank">Carnegie Mellon University</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/profile_me-480.webp 480w,/assets/img/profile_me-800.webp 800w,/assets/img/profile_me-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/profile_me.jpg?1ea036d0c4c52aaa7713e21c102baeae" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="profile_me.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p> 1612E Newell-Simon Hall </p> <p> 5000 Forbes Ave </p> <p> Pittsburgh, PA 15213 </p> </div> </div> <div class="clearfix"> <p>I am a PhD Student at <a href="https://www.ri.cmu.edu" rel="external nofollow noopener" target="_blank">The Robotics Institute</a>, Carnegie Mellon University, advised by <a href="https://www.cs.cmu.edu/~maxim/" rel="external nofollow noopener" target="_blank">Maxim Likhachev</a>. My research is driven by a profound interest in Artificial Intelligence and Robotics.</p> <p>More specifically, I am interested in developing algorithms for robotic manipulation, particularly in cluttered environments where heavy contact is essential. Additionally, I am passionate about exploring the integration of recent advancements in deep learning with the robustness of search-based planning algorithms to enhance motion planning techniques in high-dimensional spaces.</p> <p>Previously, I was a Master’s Student at <a href="https://english.tau.ac.il/" rel="external nofollow noopener" target="_blank">Tel Aviv University</a>, advised by <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/" rel="external nofollow noopener" target="_blank">Avishai Sintov</a> at <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/" rel="external nofollow noopener" target="_blank">TAU Robotics Lab</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 21, 2024</th> <td> Our work on <a href="https://x-cbs.github.io/" rel="external nofollow noopener" target="_blank">motion planning for teams of robot arms</a> has won the <strong>Best Student Paper Award</strong> at <a href="https://icaps24.icaps-conference.org" rel="external nofollow noopener" target="_blank">ICAPS 2024</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 12, 2024</th> <td> Our paper on <em>Accelerating Search-Based Planning for Multi-Robot Manipulation by Leveraging Online-Generated Experiences</em> has been accepted to <a href="https://icaps24.icaps-conference.org" rel="external nofollow noopener" target="_blank">International Conference on Automated Planning and Scheduling (ICAPS)</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 19, 2024</th> <td> Our <a href="https://arxiv.org/abs/2311.00837" rel="external nofollow noopener" target="_blank">paper</a> on <em>Constant-time Motion Planning with Anytime Refinement for Manipulation</em> has been accepted to <a href="https://2024.ieee-icra.org" rel="external nofollow noopener" target="_blank">ICRA 2024</a>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mmd-480.webp 480w,/assets/img/publication_preview/mmd-800.webp 800w,/assets/img/publication_preview/mmd-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mmd.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mmd.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mmd" class="col-sm-8"> <div class="title">Multi-Robot Motion Planning with Diffusion Models</div> <div class="author"> Yorai Shaoul * ,  <em>Itamar Mishani*</em> ,  Shivam Vats * , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jiaoyang Li, Maxim Likhachev' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/yoraish/mmd" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p> Diffusion models have recently been successfully applied to a wide range of robotics applications for learning complex multi-modal behaviors from data. However, prior works have mostly been confined to single-robot and small-scale environments due to the high sample complexity of learning multi-robot diffusion models. In this paper, we propose a method for generating collision-free multi-robot trajectories that conform to underlying data distributions while using only single-robot data. Our algorithm, Multi-robot Multi-model planning Diffusion (MMD), does so by combining learned diffusion models with classical search-based techniques – generating data-driven motions under collision constraints. Scaling further, we show how to compose multiple diffusion models to plan in large environments where a single diffusion model fails to generalize well. We demonstrate the effectiveness of our approach in planning for dozens of robots in a variety of simulated scenarios motivated by logistics environments. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mramp-480.webp 480w,/assets/img/publication_preview/mramp-800.webp 800w,/assets/img/publication_preview/mramp-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mramp.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mramp.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="xecbs" class="col-sm-8"> <div class="title">Accelerating Search-Based Planning for Multi-Robot Manipulation by Leveraging Online-Generated Experiences</div> <div class="author"> Yorai Shaoul* ,  <em>Itamar Mishani*</em> ,  Maxim Likhachev , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jiaoyang Li' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 34th International Conference on Automated Planning and Scheduling</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p> An exciting frontier in robotic manipulation is the use of multiple arms at once. However, planning concurrent motions is a challenging task using current methods. The high-dimensional composite state space renders many well-known motion planning algorithms intractable. Recently, multi-agent path finding (MAPF) algorithms have shown promise in discrete 2D domains, providing rigorous guarantees. However, widely used conflict-based methods in MAPF assume an efficient single-agent motion planner. This poses challenges in adapting them to manipulation cases where this assumption does not hold, due to the high dimensionality of configuration spaces and the computational bottlenecks associated with collision checking. To this end, we propose an approach for accelerating conflict-based search algorithms by leveraging their repetitive and incremental nature – making them tractable for use in complex scenarios involving multi-arm coordination in obstacle-laden environments. We show that our method preserves completeness and bounded sub-optimality guarantees, and demonstrate its practical efficacy through a set of experiments with up to 10 robotic arms. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ctmp-480.webp 480w,/assets/img/publication_preview/ctmp-800.webp 800w,/assets/img/publication_preview/ctmp-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/ctmp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ctmp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mishani2023constanttime" class="col-sm-8"> <div class="title">Constant-time Motion Planning with Anytime Refinement for Manipulation</div> <div class="author"> <em>Itamar Mishani</em> ,  Hayden Feddock ,  and  Maxim Likhachev </div> <div class="periodical"> <em>In 2024 IEEE International Conference on Robotics and Automation (ICRA)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Robotic manipulators are essential for future autonomous systems, yet limited trust in their autonomy has confined them to rigid, task-specific systems. The intricate configuration space of manipulators, coupled with the challenges of obstacle avoidance and constraint satisfaction, often makes motion planning the bottleneck for achieving reliable and adaptable autonomy. Recently, a class of constant-time motion planners (CTMP) was introduced. These planners employ a preprocessing phase to compute data structures that enable online planning provably guarantee the ability to generate motion plans, potentially sub-optimal, within a user defined time bound. This framework has been demonstrated to be effective in a number of time-critical tasks. However, robotic systems often have more time allotted for planning than the online portion of CTMP requires, time that can be used to improve the solution. To this end, we propose an anytime refinement approach that works in combination with CTMP algorithms. Our proposed framework, as it operates as a constant time algorithm, rapidly generates an initial solution within a user-defined time threshold. Furthermore, functioning as an anytime algorithm, it iteratively refines the solution’s quality within the allocated time budget. This enables our approach to strike a balance between guaranteed fast plan generation and the pursuit of optimization over time. We support our approach by elucidating its analytical properties, showing the convergence of the anytime component towards optimal solutions. Additionally, we provide empirical validation through simulation and real-world demonstrations on a 6 degree-of-freedom robot manipulator, applied to an assembly domain.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/paper1-480.webp 480w,/assets/img/publication_preview/paper1-800.webp 800w,/assets/img/publication_preview/paper1-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/paper1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="paper1.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="9618864" class="col-sm-8"> <div class="title">Real-Time Non-Visual Shape Estimation and Robotic Dual-Arm Manipulation Control of an Elastic Wire</div> <div class="author"> <em>Itamar Mishani</em> ,  and  Avishai Sintov </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The dual-arm manipulation of elastic wires has been a hard problem for many decades. Nevertheless, recent work has shown that the shape of a wire can be defined by a very simple representation. Theoretical analysis has stated that simple sensing of the force and torque at one end of the wire can be used to determine its shape. In this letter, we experimentally analyze the developed theoretical foundation. We deploy a dual-arm robotic system able to accurately manipulate an elastic wire. The system does not require complex visual perception and is able to reason about the shape of the wire by solely sensing forces and torques on one arm. Furthermore, we propose a full framework in which the mechanical properties of the wire are rapidly approximated in real-time. Then, a simple control rule based on Force/Torque feedback is used to manipulate the wire to some goal or track a planned path. We conduct various experiments on a full-scale system to analyze pose estimation and control accuracies. Results validate the benefit of the approach and demonstrate the ability to accurately manipulate a wire.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%69%6D%69%73%68%61%6E%69@%63%6D%75.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0002-2731-7441" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=Itamar%20Mishani" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/imishani" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/imishani@gmail.com" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/ItamarMishani" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://www.ri.cmu.edu/ri-people/itamar-mishani/" title="Work" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-briefcase"></i></a> <a href="https://gitlab.com/imishani" title="GitLab" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-gitlab"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Reach me in any of the platforms above. I'm always happy to chat about research, collaboration opportunities, or anything else! </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Itamar Mishani. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>